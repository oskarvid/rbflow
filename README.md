# Unofficial development location for the docker implementation of rbFlow

### How to set up and run the pipeline  
The startFromDocker.sh script assumes that a certain folder structure is in place, and it is recommended that you use the same folder structure unless you want to edit the script manually to suit your own preferences.  
The simplest way to get started is to clone this repository, change the file paths as described below, install Docker and then you're good to go!  

To install Docker you can follow the appropriate instructions on Dockers website for instructions: https://docs.docker.com/engine/installation/

To install the rbFlow Docker image, run 
```
sudo docker pull oskarv/rbflow:20161130
```

Before we run the docker image, we need to configure the startFromDocker.sh script.  
First of all, run 
```
sudo docker images
```
and copy the image ID of your "oskarv/rbflow" image, open startFromDocker.sh with a text editor and paste it into "IMAGEID=" at the top of the file.  

Scroll down and change the file paths at "# Paths" to point to your reference files and the rbflow folder.

The startFromDocker.sh script has divided the pre processing and germline variant calling steps into two separate scripts called preprocessing.yaml and germline_varcall.yaml. These scripts are stored in variables called "SCRIPT1" and "SCRIPT2" respectively. At the moment there is no way to automatically run the entire pipeline without needing to manually edit the startFromDocker.sh script under the "# For Running" comment. Thus, when you run the startFromDocker.sh script, it will run the pre processing, and to run the germline variant calling steps, you need to manually edit the startFromDocker.sh script and comment out this line: 
```
docker run -t --rm $CUST_USERID -v=$REFERENCE:/References -v=$DATA:/Data -w=/Data/ $IMAGE_ID sh -c "rbFlow.rb -c $SCRIPT1 -r"
```
and uncomment this line:
``` 
#docker run -t --rm $CUST_USERID -v=$REFERENCE:/References -v=$DATA:/Data -w=/Data/ $IMAGE_ID sh -c "rbFlow.rb -c $SCRIPT2 -r" 
```

As long as you run the startFromDocker.sh script from the "run" folder you should be ready to test the pipeline with the test data that is included in the "Samples" folder. Be adviced that the pipeline will crash on the final step in the germline_varcall.yaml workflow called "VariantRecalibration" due to too few samples in the test fastq files. As long as you have a complete set of fastq files the pipeline will finish successfully though.  
To start the pipeline, go to the terminal, change your working directory to the "run" directory and run 
```
sh startFromDocker.sh
```

### Cleaning the folder between runs  
If you run the clean.sh script, you will delete everything that gets created during an analysis.  


